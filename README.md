
#  An谩lisis del Overfitting y Underfitting en rboles de Decisi贸n con el Dataset de C谩ncer de Mama

Este proyecto explora c贸mo la profundidad de un 谩rbol de decisi贸n afecta su rendimiento y c贸mo puede llevar a problemas de **overfitting** y **underfitting**. Utilizando el **Breast Cancer Wisconsin Dataset**, entrenamos varios modelos de 谩rboles de decisi贸n con diferentes profundidades y analizamos su precisi贸n en los conjuntos de datos de entrenamiento y prueba.

![Decision Tree](https://storage.googleapis.com/kaggle-datasets-images/180/384/3da2510581f9d3b902307ff8d06fe327/dataset-cover.jpg)

##  Introducci贸n

En machine learning, es crucial encontrar un equilibrio entre un modelo que sea lo suficientemente flexible para capturar patrones en los datos (sin sobreajustarse) y lo suficientemente simple para generalizar bien a datos nuevos. Este proyecto se enfoca en:

- **Entrenar modelos de 谩rboles de decisi贸n** con diferentes profundidades.
- **Evaluar el rendimiento** de cada modelo en t茅rminos de precisi贸n en el conjunto de datos de entrenamiento y prueba.
- **Visualizar los resultados** para entender mejor el comportamiento del modelo y los riesgos de **overfitting** y **underfitting**.

##  Requisitos

Para ejecutar este proyecto, necesitas tener instalado:

- **Python 3.x**
- **scikit-learn**
- **pandas**
- **matplotlib**
- **prettytable**

Puedes instalar todas las dependencias necesarias ejecutando:

```bash
pip install -r requirements.txt
```

##  C贸mo Ejecutar el Proyecto

1. **Clona este repositorio** en tu m谩quina local:

    ```bash
    git clone https://github.com/DiegoLerma/breast-cancer-decision-tree.git
    ```

2. **Navega al directorio del proyecto:**

    ```bash
    cd breast-cancer-decision-tree
    ```

3. **Abre el Jupyter Notebook en Visual Studio Code o cualquier entorno compatible:**

    ```bash
    code .
    ```

4. **Ejecuta el c贸digo en el Notebook** y observa los resultados en cada celda.

##  Resultados del An谩lisis

Durante el entrenamiento, se probaron diferentes profundidades de 谩rbol, desde 2 hasta 10 niveles. Los resultados obtenidos fueron los siguientes:

```plaintext
+-----------+--------------------+----------------+---------------+
| Max Depth | Number of Features | Train Accuracy | Test Accuracy |
+-----------+--------------------+----------------+---------------+
|     2     |         30         |     0.9271     |     0.9181    |
|     3     |         30         |     0.9799     |     0.9708    |
|     4     |         30         |     0.9925     |     0.9591    |
|     5     |         30         |     0.9925     |     0.9532    |
|     6     |         30         |     0.9975     |     0.9532    |
|     7     |         30         |      1.0       |     0.9649    |
|     8     |         30         |      1.0       |     0.9649    |
|     9     |         30         |      1.0       |     0.9649    |
|     10    |         30         |      1.0       |     0.9649    |
+-----------+--------------------+----------------+---------------+
```

###  Interpretaci贸n de Resultados

- **Underfitting (Subajuste):** Cuando la profundidad del 谩rbol es baja (por ejemplo, `max_depth=2`), el modelo no captura completamente la complejidad de los datos, lo que resulta en una precisi贸n sub贸ptima tanto en el conjunto de entrenamiento como en el de prueba.

- **Equilibrio Ideal:** Se observa un buen equilibrio en `max_depth=3`, donde la precisi贸n en el conjunto de prueba es alta y el modelo no est谩 sobreajustado. Aqu铆, el modelo captura bien los patrones subyacentes en los datos sin ajustarse demasiado a las particularidades del conjunto de entrenamiento.

- **Overfitting (Sobreajuste):** A medida que aumentamos la profundidad del 谩rbol (por ejemplo, `max_depth=7` y superior), el modelo comienza a sobreajustarse. Esto se evidencia por la precisi贸n perfecta en el conjunto de entrenamiento (`1.0`), pero una ligera disminuci贸n en la precisi贸n del conjunto de prueba. Esto indica que el modelo ha aprendido demasiado bien los detalles y el ruido del conjunto de entrenamiento, lo que perjudica su capacidad de generalizaci贸n.

##  Conceptos Clave

### Overfitting y Underfitting

- **Overfitting:** Ocurre cuando el modelo es demasiado complejo y ajusta incluso el ruido en los datos de entrenamiento. Aunque el modelo muestra alta precisi贸n en el conjunto de entrenamiento, su rendimiento en datos nuevos es pobre.

- **Underfitting:** Ocurre cuando el modelo es demasiado simple para capturar las relaciones subyacentes en los datos. Esto lleva a una baja precisi贸n tanto en el conjunto de entrenamiento como en el de prueba.

### Importancia de las Condiciones de Paro

Establecer condiciones de paro adecuadas, como limitar la profundidad m谩xima de un 谩rbol de decisi贸n, es crucial para evitar el overfitting. Es importante monitorear la precisi贸n en los conjuntos de datos de entrenamiento y prueba para determinar el punto 贸ptimo donde el modelo generaliza mejor.

##  Visualizaci贸n del rbol de Decisi贸n

Visualizar el 谩rbol de decisi贸n puede ayudar a entender c贸mo se toman las decisiones en diferentes niveles de profundidad. Puedes ejecutar el siguiente c贸digo en tu notebook para ver c贸mo se ven los 谩rboles entrenados:

```python
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

for depth in range(3,10,2):
    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)
    clf.fit(X_train, y_train)
    
    plt.figure()
    plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)
    plt.title(f"Decision Tree with max_depth={depth}")
    plt.show()
```

### Este es el ejemplo de uno de los 谩rboles generados:

![Arbol de profundidad 3](output.png)

##  Conclusiones

Este proyecto demuestra la importancia de elegir la profundidad adecuada de un 谩rbol de decisi贸n. Un modelo que es demasiado simple no captura suficiente informaci贸n (underfitting), mientras que un modelo demasiado complejo captura demasiada informaci贸n, incluyendo el ruido (overfitting). Es crucial encontrar un equilibrio para asegurar que el modelo generalice bien a nuevos datos.

##  Contribuciones

Si tienes sugerencias, mejoras o deseas reportar alg煤n problema, 隆no dudes en contribuir! Puedes abrir un issue o enviar un pull request.

##  Licencia

Este proyecto est谩 bajo la Licencia MIT. Puedes ver m谩s detalles en el archivo `LICENSE`.

---

*隆Gracias por explorar este proyecto! Esperamos que este an谩lisis te haya ayudado a entender mejor los conceptos de overfitting y underfitting, as铆 como la importancia de establecer condiciones adecuadas para la construcci贸n de modelos de machine learning.*
